{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Índice\n",
    "1. Sobre o conjunto de dados\n",
    "2. Pré-processamento de texto\n",
    "3. Usar TFIDF para melhorar o vetor de contagem\n",
    "4. Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sobre o dataset \n",
    "\n",
    "CEPs\n",
    "\n",
    "Há um total de xxx CEPs no conjunto de dados..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('rslp')\n",
    "\n",
    "# Para tratar as palavras dos textos\n",
    "import unicodedata # Conjunto de caracteres de uniformidade unicode\n",
    "import re # Regular Expression\n",
    "\n",
    "# Para possibilitar processamento paralelo\n",
    "from multiprocessing import  Pool\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_nu</th>\n",
       "      <th>ufe_sg</th>\n",
       "      <th>loc_nu</th>\n",
       "      <th>bai_nu_ini</th>\n",
       "      <th>bai_nu_fim</th>\n",
       "      <th>log_no</th>\n",
       "      <th>log_complemento</th>\n",
       "      <th>cep</th>\n",
       "      <th>int_cep</th>\n",
       "      <th>tlo_tx</th>\n",
       "      <th>log_sta_tlo</th>\n",
       "      <th>log_no_abrev</th>\n",
       "      <th>bai_no</th>\n",
       "      <th>bai_no_abrev</th>\n",
       "      <th>mun_nu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1008337</td>\n",
       "      <td>MG</td>\n",
       "      <td>4047</td>\n",
       "      <td>57341</td>\n",
       "      <td>0</td>\n",
       "      <td>Ouro Fino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38042274</td>\n",
       "      <td>38042274</td>\n",
       "      <td>Rua</td>\n",
       "      <td>S</td>\n",
       "      <td>R Ouro Fino</td>\n",
       "      <td>Damha Residencial Uberaba I</td>\n",
       "      <td>D Res Uberaba I</td>\n",
       "      <td>3170107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1008338</td>\n",
       "      <td>MG</td>\n",
       "      <td>4047</td>\n",
       "      <td>57341</td>\n",
       "      <td>0</td>\n",
       "      <td>Mariana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38042276</td>\n",
       "      <td>38042276</td>\n",
       "      <td>Rua</td>\n",
       "      <td>S</td>\n",
       "      <td>R Mariana</td>\n",
       "      <td>Damha Residencial Uberaba I</td>\n",
       "      <td>D Res Uberaba I</td>\n",
       "      <td>3170107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1008339</td>\n",
       "      <td>MG</td>\n",
       "      <td>4047</td>\n",
       "      <td>57341</td>\n",
       "      <td>0</td>\n",
       "      <td>Lagoa Formosa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38042278</td>\n",
       "      <td>38042278</td>\n",
       "      <td>Rua</td>\n",
       "      <td>S</td>\n",
       "      <td>R Lga Formosa</td>\n",
       "      <td>Damha Residencial Uberaba I</td>\n",
       "      <td>D Res Uberaba I</td>\n",
       "      <td>3170107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1008340</td>\n",
       "      <td>MG</td>\n",
       "      <td>4047</td>\n",
       "      <td>57341</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38042280</td>\n",
       "      <td>38042280</td>\n",
       "      <td>Rua</td>\n",
       "      <td>S</td>\n",
       "      <td>R A</td>\n",
       "      <td>Damha Residencial Uberaba I</td>\n",
       "      <td>D Res Uberaba I</td>\n",
       "      <td>3170107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1008341</td>\n",
       "      <td>MG</td>\n",
       "      <td>4047</td>\n",
       "      <td>57341</td>\n",
       "      <td>0</td>\n",
       "      <td>Um</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38042282</td>\n",
       "      <td>38042282</td>\n",
       "      <td>Avenida</td>\n",
       "      <td>S</td>\n",
       "      <td>Av Um</td>\n",
       "      <td>Damha Residencial Uberaba I</td>\n",
       "      <td>D Res Uberaba I</td>\n",
       "      <td>3170107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    log_nu ufe_sg  loc_nu  bai_nu_ini  bai_nu_fim         log_no  \\\n",
       "0  1008337     MG    4047       57341           0      Ouro Fino   \n",
       "1  1008338     MG    4047       57341           0        Mariana   \n",
       "2  1008339     MG    4047       57341           0  Lagoa Formosa   \n",
       "3  1008340     MG    4047       57341           0              A   \n",
       "4  1008341     MG    4047       57341           0             Um   \n",
       "\n",
       "  log_complemento       cep   int_cep   tlo_tx log_sta_tlo   log_no_abrev  \\\n",
       "0             NaN  38042274  38042274      Rua           S    R Ouro Fino   \n",
       "1             NaN  38042276  38042276      Rua           S      R Mariana   \n",
       "2             NaN  38042278  38042278      Rua           S  R Lga Formosa   \n",
       "3             NaN  38042280  38042280      Rua           S            R A   \n",
       "4             NaN  38042282  38042282  Avenida           S          Av Um   \n",
       "\n",
       "                        bai_no     bai_no_abrev   mun_nu  \n",
       "0  Damha Residencial Uberaba I  D Res Uberaba I  3170107  \n",
       "1  Damha Residencial Uberaba I  D Res Uberaba I  3170107  \n",
       "2  Damha Residencial Uberaba I  D Res Uberaba I  3170107  \n",
       "3  Damha Residencial Uberaba I  D Res Uberaba I  3170107  \n",
       "4  Damha Residencial Uberaba I  D Res Uberaba I  3170107  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivo = 'ect_amostra_minas_gerais.csv'\n",
    "sep = ';'\n",
    "# ler o dataset\n",
    "df = pd.read_csv(arquivo, sep=sep)\n",
    "#df.select_dtypes(exclude=[np.number]).columns\n",
    "#df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111880, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pt.stackoverflow.com/questions/375592/como-cortar-texto-de-string-em-python-delimitando-a-substring-inicial-para-a-po  \n",
    "def split_text(obj, substring = None, start = 0, qtd = None):\n",
    "    qtd = len(obj) if qtd is None else qtd\n",
    "\n",
    "    if substring:\n",
    "        inicio = obj.find(substring)\n",
    "        return obj[inicio:inicio+qtd]\n",
    "    elif not substring:\n",
    "        return obj[start:start+qtd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna estratifica conté os 3 primeiros dígitos do CEP. Junto com ufe_sg estratifica forma o par\n",
    "# para a estratificação proporcional dos dados.\n",
    "df['estratifica'] = (df['cep']/100000).astype(int)\n",
    "\n",
    "features_all = ['log_nu', 'ufe_sg', 'loc_nu', 'bai_nu_ini', 'bai_nu_fim', 'log_no', \n",
    "            'log_complemento', 'cep', 'tlo_tx', 'log_sta_tlo', \n",
    "            'log_no_abrev', 'bai_no', 'bai_no_abrev', 'mun_nu', 'estratifica']\n",
    "#, 'cep', 'int_cep'\n",
    "\n",
    "features_num = ['log_nu','loc_nu','bai_nu_ini','bai_nu_fim','mun_nu']\n",
    "features_txt = ['ufe_sg', 'log_no', 'log_complemento', 'tlo_tx', 'log_sta_tlo', \n",
    "                'log_no_abrev', 'bai_no', 'bai_no_abrev']\n",
    "\n",
    "estratifica = ['ufe_sg','estratifica'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, df_end, y_train, y_test = train_test_split(df[features_all], df[estratifica], test_size=0.33, random_state=42)\n",
    "\n",
    "# O df_cep é criado para possibilitar a criação dos diferentes label com os dígitos do CEP.\n",
    "df_cep = pd.DataFrame()\n",
    "df_cep['cep'] = df_end['cep']\n",
    "\n",
    "# Mantém o DataFrame df[features_all] com o mesmo número de registros depois da estratificação.\n",
    "df = df_end\n",
    "\n",
    "# Elimina a feature estratifica criada exclusivamente \n",
    "# quando for necessária uma amostragem estratificada proporcional por ufe_sg e cep\n",
    "df_end = df_end.drop(columns=['estratifica'])\n",
    "\n",
    "del X_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36921, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stoplist():\n",
    "    stoplist = open(\"stopwords.txt\", \"r\")\n",
    "    stoplist = stoplist.read()\n",
    "    stoplist = set(stoplist.splitlines())\n",
    "    return stoplist\n",
    "\n",
    "stopwords = load_stoplist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/perinm/PI-2020.1/blob/master/Proj%20Final/Data%20Processing.ipynb\n",
    "def parallelize_dataframe(df, func, n_cores=8):\n",
    "    \"\"\"\n",
    "    Function that parallelizes any function applied to a dataframe\n",
    "    Input:\n",
    "    df      - Dataframe\n",
    "    func    - Function to be aplied to portions of Dataframe\n",
    "    n_cores - Number of CPU cores to be used on the application of func\n",
    "    \n",
    "    \"\"\"\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/perinm/PI-2020.1/blob/master/Proj%20Final/Data%20Processing.ipynb\n",
    "\n",
    "# Processo que cria a feature end_txt a partir dos campos que compõem um endereço\n",
    "def preprocessing_df_txt(df):\n",
    "    return df[features_txt].apply(lambda x: \" \".join(x.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36921, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/perinm/PI-2020.1/blob/master/Proj%20Final/Data%20Processing.ipynb\n",
    "\n",
    "#Paralelização do processo que cria a nova feature end_txt\n",
    "df_end['end_txt'] = parallelize_dataframe(df_end[features_txt], preprocessing_df_txt)\n",
    "df_end['end_txt'] = [re.sub(r'nan', ' ', x) for x in df_end['end_txt'].str.lower()]\n",
    "df_end.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Aplica o conjunto unicode NFKD Compatibility Decomposition  \n",
    "https://unicode.org/reports/tr15/   \n",
    "Utilização: irá retirar todas as acentuações e deixará nas letras origianais  \n",
    "Será útil quando os endereços estiverem mal escritos   \n",
    "'''\n",
    "\n",
    "def norma(old):\n",
    "    new = ''.join(ch for ch in unicodedata.normalize('NFKD', \n",
    "                    str(old)) if not unicodedata.combining(ch))\n",
    "    return new\n",
    "\n",
    "Aplica a normalização sobre a feature end_txt  \n",
    "\n",
    "df_end.end_txt = norma(df_end.end_txt)\n",
    "df_end.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36921, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_end['cep'] = df_cep.cep\n",
    "\n",
    "# Depois de usado o DataFrame df_cep será apagado para liberar de RAM\n",
    "del df_cep\n",
    "\n",
    "df_end.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A variável target **`label`** receberá **`3`** dígitos do CEP\n",
    "- É acrescido ao conjunto de `features` o `cep_2d` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384    2097\n",
       "355    1793\n",
       "394    1625\n",
       "326    1591\n",
       "380    1393\n",
       "       ... \n",
       "307     155\n",
       "301     152\n",
       "354     148\n",
       "347      57\n",
       "346      48\n",
       "Name: label, Length: 65, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Será criada uma feature cep_2d \n",
    "df_end['cep_2d'] = [int(x/1000000) for x in df_end.cep]\n",
    "\n",
    "# label CEP com 3 DÍGITOS\n",
    "df_end['label'] = [int(x/100000) for x in df_end.cep]\n",
    "\n",
    "df_end = df_end.drop(columns=['cep'])\n",
    "\n",
    "# Mantém o DataFrame df[features_all] com o mesmo número de registros depois da estratificação.\n",
    "df = df_end\n",
    "\n",
    "df_end.label.value_counts()\n",
    "#df_end.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_nu</th>\n",
       "      <th>ufe_sg</th>\n",
       "      <th>loc_nu</th>\n",
       "      <th>bai_nu_ini</th>\n",
       "      <th>bai_nu_fim</th>\n",
       "      <th>log_no</th>\n",
       "      <th>log_complemento</th>\n",
       "      <th>tlo_tx</th>\n",
       "      <th>log_sta_tlo</th>\n",
       "      <th>log_no_abrev</th>\n",
       "      <th>bai_no</th>\n",
       "      <th>bai_no_abrev</th>\n",
       "      <th>mun_nu</th>\n",
       "      <th>end_txt</th>\n",
       "      <th>cep_2d</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24505</th>\n",
       "      <td>1046029</td>\n",
       "      <td>MG</td>\n",
       "      <td>3547</td>\n",
       "      <td>4936</td>\n",
       "      <td>0</td>\n",
       "      <td>Professora Maria Hipólita Lemos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rua</td>\n",
       "      <td>S</td>\n",
       "      <td>R Prfa Maria H Lemos</td>\n",
       "      <td>Vila São José</td>\n",
       "      <td>Vl S José</td>\n",
       "      <td>3147907</td>\n",
       "      <td>mg professora maria hipólita lemos   rua s r prfa maria h lemos vila são josé vl s josé</td>\n",
       "      <td>37</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        log_nu ufe_sg  loc_nu  bai_nu_ini  bai_nu_fim  \\\n",
       "24505  1046029     MG    3547        4936           0   \n",
       "\n",
       "                                log_no log_complemento tlo_tx log_sta_tlo  \\\n",
       "24505  Professora Maria Hipólita Lemos             NaN    Rua           S   \n",
       "\n",
       "               log_no_abrev         bai_no bai_no_abrev   mun_nu  \\\n",
       "24505  R Prfa Maria H Lemos  Vila São José    Vl S José  3147907   \n",
       "\n",
       "                                                                                       end_txt  \\\n",
       "24505  mg professora maria hipólita lemos   rua s r prfa maria h lemos vila são josé vl s josé   \n",
       "\n",
       "       cep_2d  label  \n",
       "24505      37    379  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_end.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. TFIDF\n",
    "\n",
    "O TFIDF também pode ser facilmente implementado em Python usando o Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36921, 4000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# inicializar TFIDF\n",
    "vec = TfidfVectorizer(max_features=4000, stop_words=stopwords)\n",
    "# criar TFIDF\n",
    "tfidf = vec.fit_transform(df_end.end_txt)\n",
    "#tfidf_df = vec.fit_transform(df_end.end_txt)\n",
    "\n",
    "tfidf.shape\n",
    "#tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36921, 4000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix #para transformar DataFrame em Sparse DataFrame otimizado\n",
    "\n",
    "sp_vec = csr_matrix(tfidf)\n",
    "tfidf_df = pd.DataFrame.sparse.from_spmatrix(sp_vec)\n",
    "\n",
    "# amostra\n",
    "#tfidf_df.iloc[:20, 3000:3050]\n",
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "São acrescentadas as `features` que compõem o endereço + **`cep_2d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12170, 4007)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# São acrescentadas as features que compõem o endereço + cep_2d\n",
    "tfidf_df = pd.concat([df[['log_nu','loc_nu','bai_nu_ini','bai_nu_fim','mun_nu',\n",
    "                          'cep_2d','label']], tfidf_df], axis=1, join='inner')\n",
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_end, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria o modelo ML baseado nos parâmetros\n",
    "def create_model(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "               \n",
    "    model = XGBClassifier()\n",
    "    model = model.fit(X_train, y_train)\n",
    "    \n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 99.95%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# criar o modelo de classificação baseado no TFIDF\n",
    "y_pred, X_test, y_test = create_model(tfidf_df, tfidf_df.label)\n",
    "\n",
    "acuracia = accuracy_score(y_test, y_pred.predict(X_test))\n",
    "print(\"Acurácia: %.2f%%\" % (acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O primeiro teste de classificação considerando 3 dígitos do CEP como label (target).\n",
    "    - **Acurácia: 99.95%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
